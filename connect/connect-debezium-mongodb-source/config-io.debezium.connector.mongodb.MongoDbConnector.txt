==========================
MongoDB
==========================
ðŸ”˜ topic.prefix

Topic prefix that identifies and provides a namespace for the particular database server/cluster is capturing changes. The topic prefix should be unique across all other connectors, since it is used as a prefix for all Kafka topic names that receive events emitted by this connector. Only alphanumeric characters, hyphens, dots and underscores must be accepted.

	 - Type: STRING
	 - Default: null
	 - Importance: HIGH
	 - Required: false

ðŸ”˜ mongodb.connection.string

Database connection string.

	 - Type: STRING
	 - Default: null
	 - Importance: HIGH
	 - Required: false

ðŸ”˜ internal.mongodb.allow.offset.invalidation

Allows offset invalidation when required by change of connection mode

	 - Type: BOOLEAN
	 - Default: false
	 - Importance: MEDIUM
	 - Required: false

ðŸ”˜ mongodb.user

Database user for connecting to MongoDB, if necessary.

	 - Type: STRING
	 - Default: null
	 - Importance: HIGH
	 - Required: false

ðŸ”˜ mongodb.password

Password to be used when connecting to MongoDB, if necessary.

	 - Type: PASSWORD
	 - Default: null
	 - Importance: HIGH
	 - Required: false

ðŸ”˜ mongodb.authsource

Database containing user credentials.

	 - Type: STRING
	 - Default: admin
	 - Importance: MEDIUM
	 - Required: false

ðŸ”˜ mongodb.connect.timeout.ms

The connection timeout, given in milliseconds. Defaults to 10 seconds (10,000 ms).

	 - Type: INT
	 - Default: 10000
	 - Importance: LOW
	 - Required: false

ðŸ”˜ mongodb.heartbeat.frequency.ms

The frequency that the cluster monitor attempts to reach each server. Defaults to 10 seconds (10,000 ms).

	 - Type: INT
	 - Default: 10000
	 - Importance: LOW
	 - Required: false

ðŸ”˜ mongodb.socket.timeout.ms

The socket timeout, given in milliseconds. Defaults to 0 ms.

	 - Type: INT
	 - Default: 0
	 - Importance: LOW
	 - Required: false

ðŸ”˜ mongodb.server.selection.timeout.ms

The server selection timeout, given in milliseconds. Defaults to 10 seconds (10,000 ms).

	 - Type: INT
	 - Default: 30000
	 - Importance: LOW
	 - Required: false

ðŸ”˜ mongodb.poll.interval.ms

Interval for looking for new, removed, or changed replica sets, given in milliseconds. Defaults to 30 seconds (30,000 ms).

	 - Type: LONG
	 - Default: 30000
	 - Importance: MEDIUM
	 - Required: false

ðŸ”˜ mongodb.ssl.enabled

Should connector use SSL to connect to MongoDB instances

	 - Type: BOOLEAN
	 - Default: false
	 - Importance: MEDIUM
	 - Required: false

ðŸ”˜ mongodb.ssl.invalid.hostname.allowed

Whether invalid host names are allowed when using SSL. If true the connection will not prevent man-in-the-middle attacks

	 - Type: BOOLEAN
	 - Default: false
	 - Importance: MEDIUM
	 - Required: false

ðŸ”˜ cursor.max.await.time.ms

The maximum processing time in milliseconds to wait for the oplog cursor to process a single poll request

	 - Type: INT
	 - Default: null
	 - Importance: LOW
	 - Required: false

==========================
Connector
==========================
ðŸ”˜ event.processing.failure.handling.mode

Specify how failures during processing of events (i.e. when encountering a corrupted event) should be handled, including: 'fail' (the default) an exception indicating the problematic event and its position is raised, causing the connector to be stopped; 'warn' the problematic event and its position will be logged and the event will be skipped; 'ignore' the problematic event will be skipped.

	 - Type: STRING
	 - Default: fail
	 - Importance: MEDIUM
	 - Required: false

ðŸ”˜ max.batch.size

Maximum size of each batch of source records. Defaults to 2048.

	 - Type: INT
	 - Default: 2048
	 - Importance: MEDIUM
	 - Required: false

ðŸ”˜ max.queue.size

Maximum size of the queue for change events read from the database log but not yet recorded or forwarded. Defaults to 8192, and should always be larger than the maximum batch size.

	 - Type: INT
	 - Default: 8192
	 - Importance: MEDIUM
	 - Required: false

ðŸ”˜ poll.interval.ms

Time to wait for new change events to appear after receiving no events, given in milliseconds. Defaults to 500 ms.

	 - Type: LONG
	 - Default: 500
	 - Importance: MEDIUM
	 - Required: false

ðŸ”˜ max.queue.size.in.bytes

Maximum size of the queue in bytes for change events read from the database log but not yet recorded or forwarded. Defaults to 0. Mean the feature is not enabled

	 - Type: LONG
	 - Default: 0
	 - Importance: MEDIUM
	 - Required: false

ðŸ”˜ provide.transaction.metadata

Enables transaction metadata extraction together with event counting

	 - Type: BOOLEAN
	 - Default: false
	 - Importance: LOW
	 - Required: false

ðŸ”˜ skipped.operations

The comma-separated list of operations to skip during streaming, defined as: 'c' for inserts/create; 'u' for updates; 'd' for deletes, 't' for truncates, and 'none' to indicate nothing skipped. By default, only truncate operations will be skipped.

	 - Type: LIST
	 - Default: t
	 - Importance: LOW
	 - Required: false

ðŸ”˜ snapshot.delay.ms

A delay period before a snapshot will begin, given in milliseconds. Defaults to 0 ms.

	 - Type: LONG
	 - Default: 0
	 - Importance: LOW
	 - Required: false

ðŸ”˜ streaming.delay.ms

A delay period after the snapshot is completed and the streaming begins, given in milliseconds. Defaults to 0 ms.

	 - Type: LONG
	 - Default: 0
	 - Importance: LOW
	 - Required: false

ðŸ”˜ snapshot.include.collection.list

This setting must be set to specify a list of tables/collections whose snapshot must be taken on creating or restarting the connector.

	 - Type: LIST
	 - Default: null
	 - Importance: MEDIUM
	 - Required: false

ðŸ”˜ snapshot.fetch.size

The maximum number of records that should be loaded into memory while performing a snapshot.

	 - Type: INT
	 - Default: null
	 - Importance: MEDIUM
	 - Required: false

ðŸ”˜ snapshot.max.threads

The maximum number of threads used to perform the snapshot. Defaults to 1.

	 - Type: INT
	 - Default: 1
	 - Importance: MEDIUM
	 - Required: false

ðŸ”˜ snapshot.mode.custom.name

When 'snapshot.mode' is set as custom, this setting must be set to specify a the name of the custom implementation provided in the 'name()' method. The implementations must implement the 'Snapshotter' interface and is called on each app boot to determine whether to do a snapshot.

	 - Type: STRING
	 - Default: null
	 - Importance: MEDIUM
	 - Required: false

ðŸ”˜ snapshot.mode.configuration.based.snapshot.data

When 'snapshot.mode' is set as configuration_based, this setting permits to specify whenever the data should be snapshotted or not.

	 - Type: BOOLEAN
	 - Default: false
	 - Importance: MEDIUM
	 - Required: false

ðŸ”˜ snapshot.mode.configuration.based.snapshot.schema

When 'snapshot.mode' is set as configuration_based, this setting permits to specify whenever the schema should be snapshotted or not.

	 - Type: BOOLEAN
	 - Default: false
	 - Importance: MEDIUM
	 - Required: false

ðŸ”˜ snapshot.mode.configuration.based.start.stream

When 'snapshot.mode' is set as configuration_based, this setting permits to specify whenever the stream should start or not after snapshot.

	 - Type: BOOLEAN
	 - Default: false
	 - Importance: MEDIUM
	 - Required: false

ðŸ”˜ snapshot.mode.configuration.based.snapshot.on.schema.error

When 'snapshot.mode' is set as configuration_based, this setting permits to specify whenever the schema should be snapshotted or not in case of error.

	 - Type: BOOLEAN
	 - Default: false
	 - Importance: MEDIUM
	 - Required: false

ðŸ”˜ snapshot.mode.configuration.based.snapshot.on.data.error

When 'snapshot.mode' is set as configuration_based, this setting permits to specify whenever the data should be snapshotted or not in case of error.

	 - Type: BOOLEAN
	 - Default: false
	 - Importance: MEDIUM
	 - Required: false

ðŸ”˜ retriable.restart.connector.wait.ms

Time to wait before restarting connector after retriable exception occurs. Defaults to 10000ms.

	 - Type: LONG
	 - Default: 10000
	 - Importance: LOW
	 - Required: false

ðŸ”˜ query.fetch.size

The maximum number of records that should be loaded into memory while streaming. A value of '0' uses the default JDBC fetch size.

	 - Type: INT
	 - Default: 0
	 - Importance: MEDIUM
	 - Required: false

ðŸ”˜ errors.max.retries

The maximum number of retries on connection errors before failing (-1 = no limit, 0 = disabled, > 0 = num of retries).

	 - Type: INT
	 - Default: -1
	 - Importance: LOW
	 - Required: false

ðŸ”˜ incremental.snapshot.watermarking.strategy

Specify the strategy used for watermarking during an incremental snapshot: 'insert_insert' both open and close signal is written into signal data collection (default); 'insert_delete' only open signal is written on signal data collection, the close will delete the relative open signal;

	 - Type: STRING
	 - Default: INSERT_INSERT
	 - Importance: LOW
	 - Required: false

ðŸ”˜ internal.log.position.check.enable

When enabled the connector checks if the position stored in the offset is still available in the log

	 - Type: BOOLEAN
	 - Default: true
	 - Importance: MEDIUM
	 - Required: false

ðŸ”˜ internal.advanced.metrics.enable

When enabled the connector will emit advanced streaming metrics

	 - Type: BOOLEAN
	 - Default: false
	 - Importance: MEDIUM
	 - Required: false

ðŸ”˜ snapshot.mode

The criteria for running a snapshot upon startup of the connector. Select one of the following snapshot options: 'initial' (default):  If the connector does not detect any offsets for the logical server name, it runs a snapshot that captures the current full state of the configured tables. After the snapshot completes, the connector begins to stream changes from the oplog. 'never': The connector does not run a snapshot. Upon first startup, the connector immediately begins reading from the beginning of the oplog.

	 - Type: STRING
	 - Default: initial
	 - Importance: LOW
	 - Required: false

ðŸ”˜ capture.mode

The method used to capture changes from MongoDB server. Options include: 'change_streams' to capture changes via MongoDB Change Streams, update events do not contain full documents; 'change_streams_update_full' (the default) to capture changes via MongoDB Change Streams, update events contain full documents

	 - Type: STRING
	 - Default: change_streams_update_full
	 - Importance: MEDIUM
	 - Required: false

ðŸ”˜ schema.name.adjustment.mode

Specify how schema names should be adjusted for compatibility with the message converter used by the connector, including: 'avro' replaces the characters that cannot be used in the Avro type name with underscore; 'avro_unicode' replaces the underscore or characters that cannot be used in the Avro type name with corresponding unicode like _uxxxx. Note: _ is an escape sequence like backslash in Java;'none' does not apply any adjustment (default)

	 - Type: STRING
	 - Default: none
	 - Importance: LOW
	 - Required: false

==========================
Events
==========================
ðŸ”˜ converters

Optional list of custom converters that would be used instead of default ones. The converters are defined using '<converter.prefix>.type' config option and configured using options '<converter.prefix>.<option>'

	 - Type: STRING
	 - Default: null
	 - Importance: LOW
	 - Required: false

ðŸ”˜ post.processors

Optional list of post processors. The processors are defined using '<post.processor.prefix>.type' config option and configured using options '<post.processor.prefix.<option>'

	 - Type: STRING
	 - Default: null
	 - Importance: LOW
	 - Required: false

ðŸ”˜ tombstones.on.delete

Whether delete operations should be represented by a delete event and a subsequent tombstone event (true) or only by a delete event (false). Emitting the tombstone event (the default behavior) allows Kafka to completely delete all events pertaining to the given key once the source record got deleted.

	 - Type: BOOLEAN
	 - Default: true
	 - Importance: MEDIUM
	 - Required: false

ðŸ”˜ heartbeat.interval.ms

Length of an interval in milli-seconds in in which the connector periodically sends heartbeat messages to a heartbeat topic. Use 0 to disable heartbeat messages. Disabled by default.

	 - Type: INT
	 - Default: 0
	 - Importance: MEDIUM
	 - Required: false

ðŸ”˜ heartbeat.topics.prefix

The prefix that is used to name heartbeat topics.Defaults to __debezium-heartbeat.

	 - Type: STRING
	 - Default: __debezium-heartbeat
	 - Importance: LOW
	 - Required: false

ðŸ”˜ signal.data.collection

The name of the data collection that is used to send signals/commands to Debezium. Signaling is disabled when not set.

	 - Type: STRING
	 - Default: null
	 - Importance: MEDIUM
	 - Required: false

ðŸ”˜ signal.poll.interval.ms

Interval for looking for new signals in registered channels, given in milliseconds. Defaults to 5 seconds.

	 - Type: LONG
	 - Default: 5000
	 - Importance: MEDIUM
	 - Required: false

ðŸ”˜ signal.enabled.channels

List of channels names that are enabled. Source channel is enabled by default

	 - Type: LIST
	 - Default: source
	 - Importance: MEDIUM
	 - Required: false

ðŸ”˜ topic.naming.strategy

The name of the TopicNamingStrategy class that should be used to determine the topic name for data change, schema change, transaction, heartbeat event etc.

	 - Type: CLASS
	 - Default: io.debezium.schema.SchemaTopicNamingStrategy
	 - Importance: MEDIUM
	 - Required: false

ðŸ”˜ notification.enabled.channels

List of notification channels names that are enabled.

	 - Type: LIST
	 - Default: null
	 - Importance: MEDIUM
	 - Required: false

ðŸ”˜ notification.sink.topic.name

The name of the topic for the notifications. This is required in case 'sink' is in the list of enabled channels

	 - Type: STRING
	 - Default: null
	 - Importance: HIGH
	 - Required: false

ðŸ”˜ transaction.metadata.factory

Class to make transaction context & transaction struct/schemas

	 - Type: CLASS
	 - Default: io.debezium.pipeline.txmetadata.DefaultTransactionMetadataFactory
	 - Importance: LOW
	 - Required: false

ðŸ”˜ custom.metric.tags

The custom metric tags will accept key-value pairs to customize the MBean object name which should be appended the end of regular name, each key would represent a tag for the MBean object name, and the corresponding value would be the value of that tag the key is. For example: k1=v1,k2=v2

	 - Type: LIST
	 - Default: null
	 - Importance: LOW
	 - Required: false

ðŸ”˜ database.include.list

A comma-separated list of regular expressions or literals that match the database names for which changes are to be captured

	 - Type: LIST
	 - Default: null
	 - Importance: HIGH
	 - Required: false

ðŸ”˜ database.exclude.list

A comma-separated list of regular expressions or literals that match the database names for which changes are to be excluded

	 - Type: LIST
	 - Default: null
	 - Importance: HIGH
	 - Required: false

ðŸ”˜ collection.include.list

A comma-separated list of regular expressions or literals that match the collection names for which changes are to be captured

	 - Type: LIST
	 - Default: null
	 - Importance: HIGH
	 - Required: false

ðŸ”˜ collection.exclude.list

A comma-separated list of regular expressions or literals that match the collection names for which changes are to be excluded

	 - Type: STRING
	 - Default: null
	 - Importance: MEDIUM
	 - Required: false

ðŸ”˜ field.exclude.list

A comma-separated list of the fully-qualified names of fields that should be excluded from change event message values

	 - Type: STRING
	 - Default: null
	 - Importance: MEDIUM
	 - Required: false

ðŸ”˜ field.renames

A comma-separated list of the fully-qualified replacements of fields that should be used to rename fields in change event message values. Fully-qualified replacements for fields are of the form databaseName.collectionName.fieldName.nestedFieldName:newNestedFieldName, where databaseName and collectionName may contain the wildcard (*) which matches any characters, the colon character (:) is used to determine rename mapping of field.

	 - Type: STRING
	 - Default: null
	 - Importance: MEDIUM
	 - Required: false

ðŸ”˜ snapshot.collection.filter.overrides

This property contains a comma-separated list of <dbName>.<collectionName>, for which  the initial snapshot may be a subset of data present in the data source. The subset would be defined by mongodb filter query specified as value for property snapshot.collection.filter.override.<dbname>.<collectionName>

	 - Type: STRING
	 - Default: null
	 - Importance: MEDIUM
	 - Required: false

ðŸ”˜ sourceinfo.struct.maker

The name of the SourceInfoStructMaker class that returns SourceInfo schema and struct.

	 - Type: CLASS
	 - Default: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker
	 - Importance: LOW
	 - Required: false

